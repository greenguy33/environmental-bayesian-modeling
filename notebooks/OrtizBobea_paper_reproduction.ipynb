{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbc448d-ccc9-40ef-969c-05a16590832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (pytensor.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import pymc as pm\n",
    "from pymc import do, observe\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OrdinalEncoder\n",
    "from pytensor import tensor as pt\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import itertools as it\n",
    "import country_converter as cc\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7e8c0b9-df20-4d61-a046-3b2ff71f9c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/ortiz-bobea/data2/regdata_preferred_case.csv\")\n",
    "data_len = len(data.fd_tmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad527a5-b263-4991-9b08-818042f2d40a",
   "metadata": {},
   "source": [
    "# Ortiz-bobea regression formula: \n",
    "# fd_log_tfp ~ fd_tmean + fd_tmean_sq + fd_prcp + fd_prcp_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9589bab-6c6e-4e9f-aa67-0e40db76dcd8",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c93724f-580e-4d81-b69f-4949888000df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# year and country fixed effect coefficient matrices\n",
    "year_mult_mat = [np.zeros(data_len) for year in set(data.year)]\n",
    "country_mult_mat = [np.zeros(data_len) for country in set(data.ISO3)]\n",
    "country_index = -1\n",
    "curr_country = \"\"\n",
    "for row_index, row in enumerate(data.itertuples()):\n",
    "    if row.ISO3 != curr_country:\n",
    "        country_index += 1\n",
    "        curr_country = row.ISO3\n",
    "    year_index = row.year - 1962\n",
    "    country_mult_mat[country_index][row_index] = 1\n",
    "    year_mult_mat[year_index][row_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "906ce586-f3ce-43d8-820d-625c58e6ed72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9255,)\n",
      "(9255,)\n",
      "(9255,)\n",
      "(9255,)\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as model:\n",
    "\n",
    "    fd_temp_prior = pm.Normal(\"fd_temp_prior\", np.mean(data.fd_tmean), np.std(data.fd_tmean))\n",
    "    fd_temp_std = pm.HalfNormal(\"fd_temp_std\", 10)\n",
    "    # fd_temp_posterior = pm.Normal(\"fd_temp_posterior\", fd_temp_prior, fd_temp_std, shape=(data_len))\n",
    "    fd_temp_posterior = pm.Normal(\"fd_temp_posterior\", fd_temp_prior, fd_temp_std, observed=data.fd_tmean)\n",
    "\n",
    "    fd_sq_temp_prior = pm.Normal(\"fd_sq_temp_prior\", np.mean(data.fd_tmean_sq), np.std(data.fd_tmean_sq))\n",
    "    fd_sq_temp_std = pm.HalfNormal(\"fd_sq_temp_std\", 10)\n",
    "    # fd_sq_temp_posterior = pm.Normal(\"fd_sq_temp_posterior\", fd_sq_temp_prior, fd_sq_temp_std, shape=(data_len))\n",
    "    fd_sq_temp_posterior = pm.Normal(\"fd_sq_temp_posterior\", fd_sq_temp_prior, fd_sq_temp_std, observed=data.fd_tmean_sq)\n",
    "\n",
    "    fd_precip_prior = pm.Normal(\"fd_precip_prior\", np.mean(data.fd_prcp), np.std(data.fd_prcp))\n",
    "    fd_precip_std = pm.HalfNormal(\"fd_precip_std\", 10)\n",
    "    # fd_precip_posterior = pm.Normal(\"fd_precip_posterior\", fd_precip_prior, fd_precip_std, shape=(data_len))\n",
    "    fd_precip_posterior = pm.Normal(\"fd_precip_posterior\", fd_precip_prior, fd_precip_std, observed=data.fd_prcp)\n",
    "\n",
    "    fd_sq_precip_prior = pm.Normal(\"fd_sq_precip_prior\", np.mean(data.fd_prcp_sq), np.std(data.fd_prcp_sq))\n",
    "    fd_sq_precip_std = pm.HalfNormal(\"fd_sq_precip_std\", 10)\n",
    "    # fd_sq_precip_posterior = pm.Normal(\"fd_sq_precip_posterior\", fd_sq_precip_prior, fd_sq_precip_std, shape=(data_len))\n",
    "    fd_sq_precip_posterior = pm.Normal(\"fd_sq_precip_posterior\", fd_sq_precip_prior, fd_sq_precip_std, observed=data.fd_prcp_sq)\n",
    "\n",
    "    tfp_intercept = pm.Normal('tfp_intercept',0,10)\n",
    "    fd_temp_tfp_coef = pm.Normal('fd_temp_tfp_coef',0,10)\n",
    "    fd_sq_temp_tfp_coef = pm.Normal('fd_sq_temp_tfp_coef',0,10)\n",
    "    fd_precip_tfp_coef = pm.Normal(\"fd_precip_tfp_coef\",0,10)\n",
    "    fd_sq_precip_tfp_coef = pm.Normal(\"fd_sq_precip_tfp_coef\",0,10)\n",
    "\n",
    "    year_coefs = pt.expand_dims(pm.Normal(\"year_coefs\", 0, 10, shape=(len(set(data.year)))),axis=1)\n",
    "    year_fixed_effects = pm.Deterministic(\"year_fixed_effects\",pt.sum((year_coefs*year_mult_mat),axis=0))\n",
    "\n",
    "    country_coefs = pt.expand_dims(pm.Normal(\"country_coefs\", 0, 10, shape=(len(set(data.ISO3)))),axis=1)\n",
    "    country_fixed_effects = pm.Deterministic(\"country_fixed_effects\",pt.sum((country_coefs*country_mult_mat),axis=0))\n",
    "\n",
    "    print(country_fixed_effects.eval().shape)\n",
    "    print(year_fixed_effects.eval().shape)\n",
    "    \n",
    "    tfp_prior = pm.Deterministic(\n",
    "        \"tfp_prior\",\n",
    "        tfp_intercept +\n",
    "        (fd_temp_tfp_coef * fd_temp_posterior) +\n",
    "        (fd_sq_temp_tfp_coef * fd_sq_temp_posterior) +\n",
    "        (fd_precip_tfp_coef * fd_precip_posterior) +\n",
    "        (fd_sq_precip_tfp_coef * fd_sq_precip_posterior) +\n",
    "        year_fixed_effects +\n",
    "        country_fixed_effects\n",
    "    )\n",
    "    \n",
    "    tfp_std = pm.HalfNormal('tfp_std', sigma=10)\n",
    "    # tfp_posterior = pm.Normal('tfp_posterior', mu=tfp_prior, sigma=tfp_std, shape=(data_len))\n",
    "    tfp_posterior = pm.Normal('tfp_posterior', mu=tfp_prior, sigma=tfp_std, observed=data.fd_log_tfp)\n",
    "\n",
    "    # prior = pm.sample_prior_predictive()\n",
    "    # trace = pm.sample()\n",
    "    # posterior = pm.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf42662-9073-4fd4-8b9f-dfd900919068",
   "metadata": {},
   "source": [
    "# Add observed data to model and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bda6aa9b-472a-4c62-bed8-dacf9f52ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [fd_precip_posterior, fd_precip_prior, fd_precip_std, fd_precip_tfp_coef, fd_sq_precip_posterior, fd_sq_precip_prior, fd_sq_precip_std, fd_sq_precip_tfp_coef, fd_sq_temp_posterior, fd_sq_temp_prior, fd_sq_temp_std, fd_sq_temp_tfp_coef, fd_temp_posterior, fd_temp_prior, fd_temp_std, fd_temp_tfp_coef, tfp_intercept, tfp_posterior, tfp_std]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [fd_temp_prior, fd_temp_std, fd_sq_temp_prior, fd_sq_temp_std, fd_precip_prior, fd_precip_std, fd_sq_precip_prior, fd_sq_precip_std, tfp_intercept, fd_temp_tfp_coef, fd_sq_temp_tfp_coef, fd_precip_tfp_coef, fd_sq_precip_tfp_coef, tfp_std]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 02:47&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 199 seconds.\n",
      "Sampling: [fd_precip_posterior, fd_sq_precip_posterior, fd_sq_temp_posterior, fd_temp_posterior, tfp_posterior]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "observed_model = observe(model, {\n",
    "    \"fd_temp_posterior\":data.fd_tmean,\n",
    "    \"fd_sq_temp_posterior\":data.fd_tmean_sq,\n",
    "    \"fd_precip_posterior\":data.fd_prcp,\n",
    "    \"fd_sq_precip_posterior\":data.fd_prcp_sq,\n",
    "    \"tfp_posterior\":data.fd_log_tfp\n",
    "})\n",
    "\n",
    "with observed_model:\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    trace = pm.sample()\n",
    "    posterior = pm.sample_posterior_predictive(trace, extend_inferencedata=True)\n",
    "\n",
    "with open ('../models/ortiz-bobea-reproduction-year-country-fixed-effects.pkl', 'wb') as buff:\n",
    "    pkl.dump({\n",
    "        \"prior\":prior,\n",
    "        \"trace\":trace,\n",
    "        \"posterior\":posterior\n",
    "    },buff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3772369-b6b8-4851-a362-d5ff658ef67d",
   "metadata": {},
   "source": [
    "# Estimate historical anthropogenic effect on TFP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe55d928-9638-4af4-8ab1-a598a8ff7b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green months\n",
    "green_months = {}\n",
    "green_month_data = pd.read_csv(\"../data/ortiz-bobea/data2/ndvi_co/peak_bottom_ndvi_month_country.csv\")\n",
    "for row in green_month_data.itertuples():\n",
    "    peak = row[5]\n",
    "    season = [i for i in range(peak-2,peak+3)]\n",
    "    for i in range(len(season)):\n",
    "        if season[i] < 1:\n",
    "            season[i] = season[i] + 12\n",
    "        elif season[i] > 12:\n",
    "            season[i] = season[i] - 12\n",
    "    green_months[row.ISO3] = season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "4f58a697-6b17-4a31-a3e6-b7c9b4ffc64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCC-CSM2-MR\n",
      "CanESM5\n",
      "CNRM-CM6-1\n",
      "HadGEM3-GC31-LL\n",
      "IPSL-CM6A-LR\n",
      "MIROC6\n",
      "MRI-ESM2-0\n"
     ]
    }
   ],
   "source": [
    "gcms = [\"BCC-CSM2-MR\",\"CanESM5\",\"CNRM-CM6-1\",\"HadGEM3-GC31-LL\",\"IPSL-CM6A-LR\",\"MIROC6\",\"MRI-ESM2-0\"]\n",
    "gcm_data = {gcm:{\"hist_temp\":{},\"hist_prcp\":{},\"hist_nat_temp\":{},\"hist_nat_prcp\":{}} for gcm in gcms}\n",
    "\n",
    "for gcm in gcms:\n",
    "    print(gcm)\n",
    "    try:\n",
    "        hist_data = pd.read_csv(f\"../data/ortiz-bobea/data2/CMIP6_co/historical_{gcm}_1948-2020_cropland.csv\")\n",
    "    except FileNotFoundError:\n",
    "        hist_data = pd.read_csv(f\"../data/ortiz-bobea/data2/CMIP6_co/historical_{gcm}_1950-2020_cropland.csv\")\n",
    "    try:\n",
    "        hist_nat_data = pd.read_csv(f\"../data/ortiz-bobea/data2/CMIP6_co/hist-nat_{gcm}_1948-2020_cropland.csv\")\n",
    "    except FileNotFoundError:\n",
    "        hist_nat_data = pd.read_csv(f\"../data/ortiz-bobea/data2/CMIP6_co/hist-nat_{gcm}_1950-2020_cropland.csv\")\n",
    "\n",
    "    hist_temp, hist_nat_temp, hist_prcp, hist_nat_prcp = {key:[] for key in list(set(data.ISO3))}, {key:[] for key in list(set(data.ISO3))}, {key:[] for key in list(set(data.ISO3))}, {key:[] for key in list(set(data.ISO3))}\n",
    "    \n",
    "    for year in range(1961,2021):\n",
    "        for country in set(data.ISO3):\n",
    "    \n",
    "            hist_rows = hist_data.loc[(hist_data[\"year\"] == year) & (hist_data[\"ISO3\"] == country)]\n",
    "            hist_rows = [row for row in hist_rows.itertuples() if row.month in green_months[country]]\n",
    "        \n",
    "            nat_rows = hist_nat_data.loc[(hist_nat_data[\"year\"] == year) & (hist_nat_data[\"ISO3\"] == country)]\n",
    "            nat_rows = [row for row in nat_rows.itertuples() if row.month in green_months[country]]\n",
    "            \n",
    "            hist_temp[country].append(np.mean([((row.tasmax + row.tasmin)/2)-273.15 for row in hist_rows]))\n",
    "            hist_prcp[country].append(np.sum([row.pr for row in hist_rows]))\n",
    "        \n",
    "            hist_nat_temp[country].append(np.mean([((row.tasmax + row.tasmin)/2)-273.15 for row in nat_rows]))\n",
    "            hist_nat_prcp[country].append(np.sum([row.pr for row in nat_rows]))\n",
    "\n",
    "    gcm_data[gcm][\"hist_temp\"] = hist_temp\n",
    "    gcm_data[gcm][\"hist_prcp\"] = hist_prcp\n",
    "    gcm_data[gcm][\"hist_nat_temp\"] = hist_nat_temp\n",
    "    gcm_data[gcm][\"hist_nat_prcp\"] = hist_nat_prcp\n",
    "\n",
    "with open (\"../data/ortiz-bobea/data2/gcm_data.pkl\", 'wb') as buff:\n",
    "    pkl.dump(gcm_data,buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02f0ec69-c604-4fab-813c-dbd28f9e0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace = pd.read_pickle('../models/ortiz-bobea-reproduction-year-country-fixed-effects.pkl')[\"trace\"]\n",
    "gcm_data = pd.read_pickle(\"../data/ortiz-bobea/data2/gcm_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35675939-6825-46dc-aea1-9fa9554b9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef1 = trace.posterior.fd_temp_tfp_coef.data.flatten()\n",
    "coef2 = trace.posterior.fd_sq_temp_tfp_coef.data.flatten()\n",
    "coef3 = trace.posterior.fd_precip_tfp_coef.data.flatten()\n",
    "coef4 = trace.posterior.fd_sq_precip_tfp_coef.data.flatten()\n",
    "# coef1=[-7.774284e-03,-9.106163e-03,2.237827e-04,-1.279122e-02,-3.066498e-03,-9.331451e-03,-2.837678e-03,-1.034688e-02,-3.141956e-04,-1.008950e-02]\n",
    "# coef2=[5.822780e-05,4.438732e-05,-1.736405e-04,1.227045e-04,-1.416188e-04,5.294643e-05,-2.175081e-04,1.405300e-04,-1.737980e-04,6.780401e-05]\n",
    "# coef3=[2.626333e-04,1.473205e-04,2.151584e-04,1.722369e-04,2.235674e-04,2.109962e-04,2.151249e-04,2.049795e-04,1.544933e-04,1.784246e-04]\n",
    "# coef4=[-2.704724e-07,-1.242315e-07,-2.438181e-07,-1.666162e-07,-2.420376e-07,-1.927169e-07,-2.217054e-07,-2.093278e-07,-1.670311e-07,-1.892745e-07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81ba0af6-25d8-4b00-b2b9-44d0bf72a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue Weights\n",
    "revenue_data = pd.read_csv(\"../data/ortiz-bobea/data/TFP_USDA/revenue_shares.csv\")\n",
    "country_weights = {}\n",
    "for row in revenue_data.itertuples():\n",
    "    if row[3] in set(data.ISO3):\n",
    "        country_weights[row[3]] = np.mean([row[5],row[6],row[7],row[8],row[9],row[10]])\n",
    "weight_sum = sum(list(country_weights.values()))\n",
    "for country, val in country_weights.items():\n",
    "    country_weights[country] = val/weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cddc20b0-89ce-4158-a118-127455eda5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical climate means\n",
    "country_climate_means = {}\n",
    "country_1961_means = {}\n",
    "ccm_file = pd.read_csv(\"../data/ortiz-bobea/data2/country_climate_means.csv\")\n",
    "for row in ccm_file.itertuples():\n",
    "    country_climate_means[row[2]] = {\"mean_temp\":row[3], \"mean_prcp\":row[4]}\n",
    "c1961_file = pd.read_csv(\"../data/ortiz-bobea/data2/country_climate_1961.csv\")\n",
    "for row in c1961_file.itertuples():\n",
    "    country_1961_means[row[2]] = {\"mean_temp\":row[6],\"mean_prcp\":row[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3a84be-6c53-4af6-991d-bc64e4707fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_hist_dev, temp_nat_dev, prcp_hist_dev, prcp_nat_dev = {}, {}, {}, {}\n",
    "t1, t2, p1, p2 = {}, {}, {}, {}\n",
    "t_diff, t_2_diff, p_diff, p_2_diff, = {}, {}, {}, {}\n",
    "\n",
    "for gcm in gcm_data:\n",
    "    \n",
    "    temp_hist_dev[gcm] = {}\n",
    "    temp_nat_dev[gcm] = {}\n",
    "    prcp_hist_dev[gcm] = {}\n",
    "    prcp_nat_dev[gcm] = {}\n",
    "    t1[gcm] = {}\n",
    "    t2[gcm] = {}\n",
    "    p1[gcm] = {}\n",
    "    p2[gcm] = {}\n",
    "    t_diff[gcm] = {}\n",
    "    p_diff[gcm] = {}\n",
    "    t_2_diff[gcm] = {}\n",
    "    p_2_diff[gcm] = {}\n",
    "    \n",
    "    for country in set(data.ISO3):\n",
    "    \n",
    "        temp_hist_dev[gcm][country] = np.array(gcm_data[gcm][\"hist_temp\"][country]) - country_climate_means[country][\"mean_temp\"]\n",
    "        temp_nat_dev[gcm][country] = np.array(gcm_data[gcm][\"hist_nat_temp\"][country]) - country_climate_means[country][\"mean_temp\"]\n",
    "        prcp_hist_dev[gcm][country] = 1 + (np.array(gcm_data[gcm][\"hist_prcp\"][country]) - country_climate_means[country][\"mean_prcp\"]) / country_climate_means[country][\"mean_prcp\"]\n",
    "        prcp_nat_dev[gcm][country] = 1 + (np.array(gcm_data[gcm][\"hist_nat_prcp\"][country]) - country_climate_means[country][\"mean_prcp\"]) / country_climate_means[country][\"mean_prcp\"]\n",
    "        \n",
    "        t1[gcm][country] = temp_nat_dev[gcm][country] + country_1961_means[country][\"mean_temp\"]\n",
    "        t2[gcm][country] = temp_hist_dev[gcm][country] + country_1961_means[country][\"mean_temp\"]\n",
    "        p1[gcm][country] = prcp_nat_dev[gcm][country] * country_1961_means[country][\"mean_prcp\"]\n",
    "        p2[gcm][country] = prcp_hist_dev[gcm][country] * country_1961_means[country][\"mean_prcp\"]\n",
    "    \n",
    "        t_diff[gcm][country] = t2[gcm][country] - t1[gcm][country]\n",
    "        p_diff[gcm][country] = p2[gcm][country] - p1[gcm][country]\n",
    "        t_2_diff[gcm][country] = pow(t2[gcm][country],2) - pow(t1[gcm][country],2)\n",
    "        p_2_diff[gcm][country] = pow(p2[gcm][country],2) - pow(p1[gcm][country],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "757fb300-b5ec-44e4-9526-9ec574133820",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.23769493458472346 0.131996054362902\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "gcm_sample = random.choices(list(gcm_data.keys()), k=len(coef1))\n",
    "global_impacts = []\n",
    "country_res = {}\n",
    "for country in set(data.ISO3):\n",
    "    country_res[country] = []\n",
    "    for i in range(len(coef1)):\n",
    "        country_res[country].append(\n",
    "            t_diff[gcm_sample[i]][country]*coef1[i] + \n",
    "            t_2_diff[gcm_sample[i]][country]*coef2[i] + \n",
    "            p_diff[gcm_sample[i]][country]*coef3[i] + \n",
    "            p_2_diff[gcm_sample[i]][country]*coef4[i]\n",
    "            )\n",
    "gcm_global_impacts = []\n",
    "for coef in range(len(coef1)):\n",
    "    coef_vals = []\n",
    "    for year in range(0,60):\n",
    "        year_vals = []\n",
    "        for country, values in country_res.items():\n",
    "            year_vals.append(values[coef][year] * country_weights[country])\n",
    "        coef_vals.append(np.sum(year_vals))\n",
    "    gcm_global_impacts.append(np.cumsum(coef_vals))\n",
    "global_impacts.append([arr[-1] for arr in gcm_global_impacts])\n",
    "\n",
    "print(np.mean(global_impacts),np.std(global_impacts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bbc06-4514-4820-8ae5-9d57067dcadd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
