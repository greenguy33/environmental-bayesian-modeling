{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec05f3fb-ca1d-4d05-ab85-d304007c5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import random\n",
    "from pytensor import tensor as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39b1cf4a-de8a-4b57-97ef-f8c8e9ebc56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q3/myxq41dd4_9c_rx76zlk8f3r0000gn/T/ipykernel_41576/2567336226.py:17: RuntimeWarning: Mean of empty slice\n",
      "  result_dict[\"Avg_PopWeighted_Temp\"].append(np.nanmean(all_vals_by_year))\n"
     ]
    }
   ],
   "source": [
    "# create formatted dataset from pop-weighted country temp data by month\n",
    "result_dict = {\"Country\":[],\"Year\":[],\"Avg_PopWeighted_Temp\":[]}\n",
    "# data = pd.read_csv(\"../data/burke/data/input/nc/pop_weighted_country_temps_by_month.csv\")\n",
    "data = pd.read_csv(\"../data/burke/data/input/nc/unweighted_country_temps_by_month.csv\")\n",
    "col_prefix = \"unweighted_monthly_temp.mean.X\"\n",
    "years = [str(year) for year in list(range(1900,2018))]\n",
    "months = [str(month) if month >= 10 else \"0\"+str(month) for month in list(range(1,13))]\n",
    "for _, row in data.iterrows():\n",
    "    country = row[\"country\"]\n",
    "    for year in years:\n",
    "        all_vals_by_year = []\n",
    "        for month in months:\n",
    "            col_name = col_prefix + year + \".\" + month + \".01\"\n",
    "            all_vals_by_year.append(row[col_name])\n",
    "        result_dict[\"Country\"].append(country)\n",
    "        result_dict[\"Year\"].append(year)\n",
    "        result_dict[\"Mean_Temp\"].append(np.nanmean(all_vals_by_year))\n",
    "pd.DataFrame.from_dict(result_dict).to_csv(\"../data/burke/data/input/custom_monthly_unweighted_temp_by_country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e25d0c03-b5a1-40d3-bf8e-693834a360f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q3/myxq41dd4_9c_rx76zlk8f3r0000gn/T/ipykernel_84609/218810235.py:19: RuntimeWarning: Mean of empty slice\n",
      "  result_dict[\"Unweighted_Precipitation\"].append(np.nanmean(all_vals_by_year))\n"
     ]
    }
   ],
   "source": [
    "# create formatted dataset from unweighted country precip data by month\n",
    "result_dict = {\"Country\":[],\"Year\":[],\"Unweighted_Precipitation\":[]}\n",
    "# data = pd.read_csv(\"../data/burke/data/input/nc/pop_weighted_country_temps_by_month.csv\")\n",
    "data = pd.read_csv(\"../data/burke/data/input/nc/unweighted_country_precip_by_month.csv\")\n",
    "col_prefix = \"unweighted_monthly_precip.mean.precip_clipped_by_country_mask_\"\n",
    "years = [str(year) for year in list(range(1900,2018))]\n",
    "months = [str(month) if month >= 10 else \"0\"+str(month) for month in list(range(1,13))]\n",
    "month_count = 0\n",
    "for _, row in data.iterrows():\n",
    "    month_count += 1\n",
    "    country = row[\"country\"]\n",
    "    for year in years:\n",
    "        all_vals_by_year = []\n",
    "        for month in months:\n",
    "            col_name = col_prefix + str(month_count)\n",
    "            all_vals_by_year.append(row[col_name])\n",
    "        result_dict[\"Country\"].append(country)\n",
    "        result_dict[\"Year\"].append(year)\n",
    "        result_dict[\"Unweighted_Precipitation\"].append(np.nanmean(all_vals_by_year))\n",
    "pd.DataFrame.from_dict(result_dict).to_csv(\"../data/burke/data/input/custom_monthly_unweighted_precip_by_country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ead7bc4-ea4f-42de-ae2d-3490584c72df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling: [drought_posterior, drought_temp_coef_matrix, temp_posterior, temp_prior, temp_std]\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [temp_prior, temp_std, drought_temp_coef_matrix]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 00:06&lt;00:00 Sampling 4 chains, 385 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 28 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "There were 385 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Sampling: [drought_posterior, temp_posterior]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='4000' class='' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4000/4000 00:01&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cont_data = [i for i in range(100)]\n",
    "disc_data = []\n",
    "for i in range(len(cont_data)):\n",
    "    disc_data.append(random.choice([1 if i2 < i else 0 for i2 in range(len(cont_data))]))\n",
    "for index in range(len(disc_data)):\n",
    "    if disc_data[index] == 1:\n",
    "        disc_data[index] = random.choice([0,1])\n",
    "\n",
    "with pm.Model() as model:\n",
    "    temp_prior = pm.Normal(\"temp_prior\", 50, 30)\n",
    "    temp_std = pm.HalfNormal(\"temp_std\", 30)\n",
    "    temp_posterior = pm.Normal(\"temp_posterior\", temp_prior, temp_std, observed=cont_data)\n",
    "    drought_temp_coef_matrix = pm.Normal(\"drought_temp_coef_matrix\", np.zeros((1, 2)), 10)\n",
    "    drought_temp_likelihood_coefs = pm.Deterministic(\"drought_temp_likelihood_coefs\",  pt.expand_dims(temp_posterior, axis=1) / drought_temp_coef_matrix)\n",
    "    drought_prior = pm.Deterministic(\"drought_prior\", pm.math.softmax(drought_temp_likelihood_coefs, axis=-1))\n",
    "    drought_posterior = pm.Categorical(\"drought_posterior\", drought_prior, observed=disc_data)\n",
    "    prior = pm.sample_prior_predictive()\n",
    "    trace = pm.sample()\n",
    "    posterior = pm.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6be8cce3-aa90-4f07-8e42-f866220a96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-14.26782194 -12.55610603]]\n",
      "[ 40.3102402   14.83095789  26.5531689   19.74284033  26.95302559\n",
      "  30.60122259  -5.27218147  33.56728039   4.60855218  38.52839184\n",
      "  44.53427288  70.34300879  63.04655999  29.05991549  70.9671835\n",
      "  13.76689078  78.3575228   48.25463962  90.63366081  10.16378188\n",
      "  16.64943001  28.07147489  31.56158126  35.23919002  39.91932769\n",
      "  77.50856782  20.61026046  29.41375854 127.13766116  98.22415167\n",
      " -12.05451785  23.16673241  46.72218159  11.66926631  81.24860185\n",
      "  23.42020287  15.51476525  25.10838599  26.612293    36.05452247\n",
      "  82.5847512    2.95345251  32.97057062   6.32683881  89.45406727\n",
      "  82.50293908  35.10941193  38.17476144  35.35456465  36.5212818\n",
      "  76.26779663  49.88048189  31.50412594  36.69483123  26.82544515\n",
      "  80.79949935  66.81841882  56.67701219  39.74987116  45.20926887\n",
      "  50.07489458  54.80316994  75.44914393  24.58162264  95.74527566\n",
      "  26.19675354 115.04195107  56.3259031   72.09887669  60.63196094\n",
      "  74.27352916   8.5398681   70.41773322  74.75347332  78.76112141\n",
      "  23.41989475   2.32930838  84.38217584  68.95377018  34.46651085\n",
      "  49.05655967  25.10230178  35.72820746  -2.55590012  19.4254987\n",
      "  33.14444711  66.05075364  30.38504354  63.10599269  53.29211852\n",
      " -15.62939381  72.54501813  -9.6664296   53.59009816  69.5221748\n",
      "  55.00583888  28.54694922  62.68354865   9.69653322  42.34155042]\n",
      "[0 0 0 0 1 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 0 0 1 0 0 0 1 0 0 1 1 1 0\n",
      " 0 0 0 1 0 0 0 0 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(posterior[\"posterior\"][\"drought_temp_coef_matrix\"][0][0].data)\n",
    "print(posterior[\"posterior_predictive\"][\"temp_posterior\"][0][0].data)\n",
    "print(posterior[\"posterior_predictive\"][\"drought_posterior\"][0][0].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c751d23-7e99-4bd6-ad82-519b684c6fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43\n",
      "0.5952380952380952\n",
      "0.3103448275862069\n"
     ]
    }
   ],
   "source": [
    "low_temp = []\n",
    "high_temp = []\n",
    "print(np.mean(posterior[\"posterior_predictive\"][\"drought_posterior\"][1][0].data))\n",
    "for i in range(len(posterior[\"posterior_predictive\"][\"drought_posterior\"][1][0].data)):\n",
    "    if posterior[\"posterior_predictive\"][\"temp_posterior\"][1][0].data[i] < 50:\n",
    "        low_temp.append(posterior[\"posterior_predictive\"][\"drought_posterior\"][1][0].data[i])\n",
    "    else:\n",
    "        high_temp.append(posterior[\"posterior_predictive\"][\"drought_posterior\"][1][0].data[i])\n",
    "print(np.mean(low_temp))\n",
    "print(np.mean(high_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feee9685-7f60-4e6b-9f4c-32d7fa9a2099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_data_modeling)",
   "language": "python",
   "name": "env_data_modeling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
